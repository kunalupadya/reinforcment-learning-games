{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJ4TEbWb-ySs",
    "outputId": "6a7ebbd6-d419-4354-d62d-56b64fd39acb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[rllib]==1.0.1 in /opt/conda/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.7.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (1.0.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (3.0.12)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (3.7.3)\n",
      "Requirement already satisfied: opencensus in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.7.12)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (1.35.0)\n",
      "Requirement already satisfied: gpustat in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.6.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (5.3.1)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.9.0)\n",
      "Requirement already satisfied: google in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (3.0.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (3.2.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (7.1.2)\n",
      "Requirement already satisfied: aioredis in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (1.3.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.4.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (2.25.1)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.3.4)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (3.14.0)\n",
      "Requirement already satisfied: redis<3.5.0,>=3.3.2 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (3.4.1)\n",
      "Requirement already satisfied: colorful in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.5.4)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.8.7)\n",
      "Requirement already satisfied: lz4 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (3.1.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (1.2.1)\n",
      "Requirement already satisfied: gym[atari] in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.18.0)\n",
      "Requirement already satisfied: opencv-python-headless<=4.3.0.36 in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (4.3.0.36)\n",
      "Requirement already satisfied: atari-py in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.2.6)\n",
      "Requirement already satisfied: tensorboardX in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (2.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (1.4.1)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.7/site-packages (from ray[rllib]==1.0.1) (0.1.5)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.7/site-packages (from grpcio>=1.28.1->ray[rllib]==1.0.1) (1.15.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray[rllib]==1.0.1) (3.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray[rllib]==1.0.1) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray[rllib]==1.0.1) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray[rllib]==1.0.1) (3.7.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray[rllib]==1.0.1) (20.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray[rllib]==1.0.1) (5.1.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->ray[rllib]==1.0.1) (2.10)\n",
      "Requirement already satisfied: hiredis in /opt/conda/lib/python3.7/site-packages (from aioredis->ray[rllib]==1.0.1) (1.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from google->ray[rllib]==1.0.1) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->google->ray[rllib]==1.0.1) (2.0.1)\n",
      "Requirement already satisfied: blessings>=1.6 in /opt/conda/lib/python3.7/site-packages (from gpustat->ray[rllib]==1.0.1) (1.7)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from gpustat->ray[rllib]==1.0.1) (5.8.0)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /opt/conda/lib/python3.7/site-packages (from gpustat->ray[rllib]==1.0.1) (7.352.0)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari]->ray[rllib]==1.0.1) (7.2.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari]->ray[rllib]==1.0.1) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari]->ray[rllib]==1.0.1) (1.6.0)\n",
      "Requirement already satisfied: opencv-python>=3. in /opt/conda/lib/python3.7/site-packages (from gym[atari]->ray[rllib]==1.0.1) (4.5.1.48)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]->ray[rllib]==1.0.1) (0.18.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray[rllib]==1.0.1) (0.17.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray[rllib]==1.0.1) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray[rllib]==1.0.1) (49.6.0.post20210108)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema->ray[rllib]==1.0.1) (3.4.0)\n",
      "Requirement already satisfied: opencensus-context==0.1.2 in /opt/conda/lib/python3.7/site-packages (from opencensus->ray[rllib]==1.0.1) (0.1.2)\n",
      "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from opencensus->ray[rllib]==1.0.1) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]==1.0.1) (1.52.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]==1.0.1) (2020.5)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]==1.0.1) (1.24.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]==1.0.1) (4.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]==1.0.1) (4.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]==1.0.1) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]==1.0.1) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->ray[rllib]==1.0.1) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->ray[rllib]==1.0.1) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->ray[rllib]==1.0.1) (2.8.1)\n",
      "Requirement already satisfied: pygame in /opt/conda/lib/python3.7/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ray[rllib]==1.0.1\n",
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "if not os.path.exists(\"/home/jovyan/work/PyGame-Learning-Environment\"):\n",
    "    !git clone https://github.com/ntasfi/PyGame-Learning-Environment.git /home/jovyan/work/PyGame-Learning-Environment\n",
    "        \n",
    "try:\n",
    "    import ple\n",
    "except ImportError:\n",
    "    !pip install -e /home/jovyan/work/PyGame-Learning-Environment\n",
    "\n",
    "if not os.path.exists(\"/home/jovyan/work/gym-ple\"):\n",
    "    !git clone https://github.com/lusob/gym-ple.git /home/jovyan/work/gym-ple\n",
    "\n",
    "try:\n",
    "    import gym_ple\n",
    "except ImportError:\n",
    "    !pip install -e /home/jovyan/work/gym-ple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HT49-qV_O_C",
    "outputId": "6ed8cf30-ef31-4357-f903-1127b416e2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-07 03:18:22,123\tINFO trainer.py:592 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-03-07 03:18:22,125\tINFO trainer.py:619 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m couldn't import doomish\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m Couldn't import doom\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m couldn't import doomish\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m Couldn't import doom\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m couldn't import doomish\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m Couldn't import doom\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m couldn't import doomish\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m Couldn't import doom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m couldn't import doomish\n",
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m Couldn't import doom\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m couldn't import doomish\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m Couldn't import doom\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m couldn't import doomish\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m Couldn't import doom\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m pygame 2.0.1 (SDL 2.0.14, Python 3.7.9)\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m couldn't import doomish\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m Couldn't import doom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48842)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48822)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48816)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "2021-03-07 03:18:41,809\tINFO trainable.py:255 -- Trainable.setup took 19.687 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-03-07 03:18:41,810\tWARNING util.py:40 -- Install gputil for GPU system monitoring.\n",
      "2021-03-07 03:18:41,992\tINFO trainable.py:482 -- Restored on 172.17.0.4 from checkpoint: tmp/dqn/catcher/checkpoint_492/checkpoint-492\n",
      "2021-03-07 03:18:41,994\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 492, '_timesteps_total': None, '_time_total': 3342.0823402404785, '_episodes_total': 11249}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "observations (InputLayer)    [(None, 42, 42, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 21, 21, 16)        784       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 11, 11, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv_out (Conv2D)            (None, 1, 1, 256)         991488    \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "value_out (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,000,753\n",
      "Trainable params: 1,000,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:836: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:836: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48834)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:836: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48794)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:836: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48833)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:836: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=48813)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=48837)\u001b[0m 2021-03-07 03:20:59,598\tWARNING sampler.py:741 -- More than 5001 observations for 5002 env steps are buffered in the sampler. If this is more than you expected, check that that you set a horizon on your environment correctly and that it terminates at some point. Note: In multi-agent environments, `rollout_fragment_length` sets the batch size based on environment steps, not the steps of individual agents, which can result in unexpectedly large batches. Also, you may be in evaluation waiting for your Env to terminate (batch_mode=`complete_episodes`). Make sure it does at some point.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import ray\n",
    "import ray.rllib.evaluation.rollout_worker as rw\n",
    "import ray.rllib.agents.dqn as dqn\n",
    "import ray.rllib.agents.dqn.apex as apex\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from gym_ple.ple_env import PLEEnv\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "checkpoint_root = \"tmp/dqn/catcher\"\n",
    "\n",
    "# Get Ray started\n",
    "ray.shutdown()\n",
    "ray.init(object_store_memory=4*1024**3,include_dashboard=False)\n",
    "\n",
    "#['Catcher', 'MonsterKong', 'FlappyBird', 'PixelCopter', 'PuckWorld', 'RaycastMaze', 'Snake', 'WaterWorld']:\n",
    "screen_size = 42\n",
    "def env_creator(env_config):\n",
    "    rewards = {\n",
    "                \"positive\": 1.0,\n",
    "                \"negative\": -1.0,\n",
    "                \"tick\": 0.05,\n",
    "                \"loss\": -5.0,\n",
    "                \"win\": 5.0\n",
    "            }\n",
    "    return PLEEnv(game_name='Catcher',display_screen=False, width=screen_size,\n",
    "                  height=screen_size)  # return an env instance\n",
    "\n",
    "register_env(\"PixelCopter-v0\", env_creator)\n",
    "\n",
    "# Setup configuration parameters\n",
    "niter = 10\n",
    "rlconfig = {\"timesteps_per_iteration\": 8000,\n",
    "            \"model\": {\"dim\": screen_size,\n",
    "                      \"conv_filters\": [[16, [4, 4], 2], [32, [4, 4], 2], [512, [11, 11], 1]],\n",
    "                      \"framestack\": True,\n",
    "                      #\"use_lstm\": True,\n",
    "                      #\"use_attention\": False,\n",
    "                      #\"lstm_cell_size\": 64,\n",
    "                      #\"max_seq_len\": 999999,\n",
    "                     },\n",
    "            \"evaluation_num_workers\": 4,\n",
    "            \"evaluation_interval\": 1,\n",
    "            \"evaluation_num_episodes\": 1000,\n",
    "            \"gamma\": 0.97,\n",
    "            \"lr\": 4e-5,\n",
    "            \"evaluation_config\": {\n",
    "                \"explore\": False\n",
    "            },\n",
    "            \"exploration_config\": {\n",
    "                \"type\": \"EpsilonGreedy\",\n",
    "                \"initial_epsilon\": 0.6,\n",
    "                \"final_epsilon\": 0.01,\n",
    "                \"epsilon_timesteps\": 2000000,  # time from initial to final\n",
    "            },\n",
    "           }\n",
    "\n",
    "cpuconfig = {\"num_envs_per_worker\": 16,\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 4,\n",
    "            }\n",
    "\n",
    "# Update default config\n",
    "config = dqn.DEFAULT_CONFIG.copy()\n",
    "config.update(rlconfig)\n",
    "config.update(cpuconfig)\n",
    "\n",
    "# Construct trainer\n",
    "agent = dqn.DQNTrainer(config=config, env=\"PixelCopter-v0\")\n",
    "\n",
    "prior_saves = glob.glob(checkpoint_root + '/checkpoint_*/checkpoint-*[0-9]')\n",
    "if len(prior_saves) != 0:\n",
    "    highest = max(prior_saves, key=lambda x: int(x.split('-',1)[1].split('.',1)[0]))\n",
    "    agent.restore(highest)\n",
    "\n",
    "# Get policy network and print summary\n",
    "policy = agent.get_policy()\n",
    "model = policy.model\n",
    "print(model.base_model.summary())\n",
    "\n",
    "# Run training iterations\n",
    "for i in range(niter):\n",
    "    # Perform one iteration of training the policy\n",
    "    result = agent.train()\n",
    "    file_name = agent.save(checkpoint_root)\n",
    "    print(\"Iteration %02d -- Mean Reward: %2.4f -- Eval Reward %2.4f\" % (i,result[\"episode_reward_mean\"],result[\"evaluation\"][\"episode_reward_mean\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import base64\n",
    "from IPython import display\n",
    "\n",
    "def gif_animate(frames,fps=5):\n",
    "    seq = []\n",
    "    for i in range(len(frames)):\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        ax.imshow(frames[i])\n",
    "        plt.axis('off')\n",
    "        fig.canvas.draw()\n",
    "        image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "        plt.close(fig)\n",
    "        seq.append(image.reshape(fig.canvas.get_width_height()[::-1] + (3,)))\n",
    "\n",
    "    imageio.mimsave('./anim.gif', seq, fps=fps)\n",
    "    return base64.b64encode(open('./anim.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "\n",
    "# Setup separate environment\n",
    "env = env_creator({})\n",
    "\n",
    "# Get function that maps combinatorial env state to one-hot state\n",
    "prep = get_preprocessor(env.observation_space)(env.observation_space)    \n",
    "    \n",
    "# Use trained policy (without exploration) to play N episodes\n",
    "N = 10\n",
    "total_reward = 0\n",
    "gifs = []\n",
    "for i in range(N):\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    if (N<=10):\n",
    "        episode = []\n",
    "        episode.append(obs)\n",
    "    while not done:\n",
    "        action = agent.compute_action(prep.transform(obs),explore=False)\n",
    "        #action = agent.compute_action(obs,explore=False)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if (N<=10):\n",
    "            episode.append(obs)\n",
    "        episode_reward += reward\n",
    "        \n",
    "    if (N<=10):\n",
    "        gifs.append(gif_animate(episode,fps=15))\n",
    "        \n",
    "    total_reward += episode_reward\n",
    "\n",
    "# Make HTML movie\n",
    "s = '<table><tr>'\n",
    "for i in range(len(gifs)):\n",
    "    s = s + '<td><img width=\"100\" src=\"data:image/gif;base64,{0}\"/></td>'.format(gifs[i].decode('ascii'))\n",
    "s = s + '</tr></table>'\n",
    "display.display(display.HTML(s))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CartPoleEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
    "        a frictionless track. The pendulum starts upright, and the goal is to\n",
    "        prevent it from falling over by increasing and reducing the cart's\n",
    "        velocity.\n",
    "    Source:\n",
    "        This environment corresponds to the version of the cart-pole problem\n",
    "        described by Barto, Sutton, and Anderson\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Cart Position             -4.8                    4.8\n",
    "        1       Cart Velocity             -Inf                    Inf\n",
    "        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        3       Pole Angular Velocity     -Inf                    Inf\n",
    "    Actions:\n",
    "        Type: Discrete(2)\n",
    "        Num   Action\n",
    "        0     Push cart to the left\n",
    "        1     Push cart to the right\n",
    "        Note: The amount the velocity that is reduced or increased is not\n",
    "        fixed; it depends on the angle the pole is pointing. This is because\n",
    "        the center of gravity of the pole increases the amount of energy needed\n",
    "        to move the cart underneath it\n",
    "    Reward:\n",
    "        Reward is 1 for every step taken, including the termination step\n",
    "    Starting State:\n",
    "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
    "    Episode Termination:\n",
    "        Pole Angle is more than 12 degrees.\n",
    "        Cart Position is more than 2.4 (center of the cart reaches the edge of\n",
    "        the display).\n",
    "        Episode length is greater than 200.\n",
    "        Solved Requirements:\n",
    "        Considered solved when the average return is greater than or equal to\n",
    "        195.0 over 100 consecutive trials.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second': 50\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = (self.masspole + self.masscart)\n",
    "        self.length = 0.5  # actually half the pole's length\n",
    "        self.polemass_length = (self.masspole * self.length)\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.kinematics_integrator = 'euler'\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds.\n",
    "        high = np.array([self.x_threshold * 2,\n",
    "                         np.finfo(np.float32).max,\n",
    "                         self.theta_threshold_radians * 2,\n",
    "                         np.finfo(np.float32).max],\n",
    "                        dtype=np.float32)\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
    "        assert self.action_space.contains(action), err_msg\n",
    "\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        force = self.force_mag if action == 1 else -self.force_mag\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "\n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        temp = (force + self.polemass_length * theta_dot ** 2 * sintheta) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / (self.length * (4.0 / 3.0 - self.masspole * costheta ** 2 / self.total_mass))\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "\n",
    "        if self.kinematics_integrator == 'euler':\n",
    "            x = x + self.tau * x_dot\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "        else:  # semi-implicit euler\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            x = x + self.tau * x_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        done = bool(\n",
    "            x < -self.x_threshold\n",
    "            or x > self.x_threshold\n",
    "            or theta < -self.theta_threshold_radians\n",
    "            or theta > self.theta_threshold_radians\n",
    "        )\n",
    "\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_done == 0:\n",
    "                logger.warn(\n",
    "                    \"You are calling 'step()' even though this \"\n",
    "                    \"environment has already returned done = True. You \"\n",
    "                    \"should always call 'reset()' once you receive 'done = \"\n",
    "                    \"True' -- any further steps are undefined behavior.\"\n",
    "                )\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return np.array(self.state), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "        self.steps_beyond_done = None\n",
    "        return np.array(self.state)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        screen_width = 600\n",
    "        screen_height = 400\n",
    "\n",
    "        world_width = self.x_threshold * 2\n",
    "        scale = screen_width/world_width\n",
    "        carty = 100  # TOP OF CART\n",
    "        polewidth = 10.0\n",
    "        polelen = scale * (2 * self.length)\n",
    "        cartwidth = 50.0\n",
    "        cartheight = 30.0\n",
    "\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "            l, r, t, b = -cartwidth / 2, cartwidth / 2, cartheight / 2, -cartheight / 2\n",
    "            axleoffset = cartheight / 4.0\n",
    "            cart = rendering.FilledPolygon([(l, b), (l, t), (r, t), (r, b)])\n",
    "            self.carttrans = rendering.Transform()\n",
    "            cart.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(cart)\n",
    "            l, r, t, b = -polewidth / 2, polewidth / 2, polelen - polewidth / 2, -polewidth / 2\n",
    "            pole = rendering.FilledPolygon([(l, b), (l, t), (r, t), (r, b)])\n",
    "            pole.set_color(.8, .6, .4)\n",
    "            self.poletrans = rendering.Transform(translation=(0, axleoffset))\n",
    "            pole.add_attr(self.poletrans)\n",
    "            pole.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(pole)\n",
    "            self.axle = rendering.make_circle(polewidth/2)\n",
    "            self.axle.add_attr(self.poletrans)\n",
    "            self.axle.add_attr(self.carttrans)\n",
    "            self.axle.set_color(.5, .5, .8)\n",
    "            self.viewer.add_geom(self.axle)\n",
    "            self.track = rendering.Line((0, carty), (screen_width, carty))\n",
    "            self.track.set_color(0, 0, 0)\n",
    "            self.viewer.add_geom(self.track)\n",
    "\n",
    "            self._pole_geom = pole\n",
    "\n",
    "        if self.state is None:\n",
    "            return None\n",
    "\n",
    "        # Edit the pole polygon vertex\n",
    "        pole = self._pole_geom\n",
    "        l, r, t, b = -polewidth / 2, polewidth / 2, polelen - polewidth / 2, -polewidth / 2\n",
    "        pole.v = [(l, b), (l, t), (r, t), (r, b)]\n",
    "\n",
    "        x = self.state\n",
    "        cartx = x[0] * scale + screen_width / 2.0  # MIDDLE OF CART\n",
    "        self.carttrans.set_translation(cartx, carty)\n",
    "        self.poletrans.set_rotation(-x[2])\n",
    "\n",
    "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "import json\n",
    "\n",
    "checkpoint_root = \"tmp/ppo/cart\"\n",
    "\n",
    "info = ray.init(ignore_reinit_error=True)\n",
    "SELECT_ENV = \"CartPole-v1\"                      # Specifies the OpenAI Gym environment for Cart Pole\n",
    "N_ITER = 10                                     # Number of training runs.\n",
    "\n",
    "config = ppo.DEFAULT_CONFIG.copy()              # PPO's default configuration. See the next code cell.\n",
    "config[\"log_level\"] = \"WARN\"                    # Suppress too many messages, but try \"INFO\" to see what can be printed.\n",
    "\n",
    "# Other settings we might adjust:\n",
    "config[\"num_workers\"] = 1                       # Use > 1 for using more CPU cores, including over a cluster\n",
    "config[\"num_sgd_iter\"] = 10                     # Number of SGD (stochastic gradient descent) iterations per training minibatch.\n",
    "                                                # I.e., for each minibatch of data, do this many passes over it to train. \n",
    "config[\"sgd_minibatch_size\"] = 250              # The amount of data records per minibatch\n",
    "config[\"model\"][\"fcnet_hiddens\"] = [100, 50]    #\n",
    "config[\"num_cpus_per_worker\"] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "\n",
    "agent = ppo.PPOTrainer(config, env=SELECT_ENV)\n",
    "\n",
    "results = []\n",
    "episode_data = []\n",
    "episode_json = []\n",
    "\n",
    "for n in range(N_ITER):\n",
    "    result = agent.train()\n",
    "    results.append(result)\n",
    "    \n",
    "    episode = {'n': n, \n",
    "               'episode_reward_min': result['episode_reward_min'], \n",
    "               'episode_reward_mean': result['episode_reward_mean'], \n",
    "               'episode_reward_max': result['episode_reward_max'],  \n",
    "               'episode_len_mean': result['episode_len_mean']}\n",
    "    \n",
    "    episode_data.append(episode)\n",
    "    episode_json.append(json.dumps(episode))\n",
    "    file_name = agent.save(checkpoint_root)\n",
    "    \n",
    "    print(f'{n:3d}: Min/Mean/Max reward: {result[\"episode_reward_min\"]:8.4f}/{result[\"episode_reward_mean\"]:8.4f}/{result[\"episode_reward_max\"]:8.4f}. Checkpoint saved to {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_root = \"tmp/ppo/taxi\"\n",
    "\n",
    "info = ray.init(ignore_reinit_error=True)\n",
    "SELECT_ENV = \"Taxi-v3\"                      # Specifies the OpenAI Gym environment for Taxi-v3\n",
    "N_ITER = 10                                     # Number of training runs.\n",
    "\n",
    "config = ppo.DEFAULT_CONFIG.copy()              # PPO's default configuration. See the next code cell.\n",
    "config[\"log_level\"] = \"WARN\"                    # Suppress too many messages, but try \"INFO\" to see what can be printed.\n",
    "\n",
    "# Other settings we might adjust:\n",
    "config[\"num_workers\"] = 1                       # Use > 1 for using more CPU cores, including over a cluster\n",
    "config[\"num_sgd_iter\"] = 10                     # Number of SGD (stochastic gradient descent) iterations per training minibatch.\n",
    "                                                # I.e., for each minibatch of data, do this many passes over it to train. \n",
    "config[\"sgd_minibatch_size\"] = 250              # The amount of data records per minibatch\n",
    "config[\"model\"][\"fcnet_hiddens\"] = [100, 50]    #\n",
    "config[\"num_cpus_per_worker\"] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "\n",
    "agent = ppo.PPOTrainer(config, env=SELECT_ENV)\n",
    "\n",
    "results = []\n",
    "episode_data = []\n",
    "episode_json = []\n",
    "\n",
    "for n in range(N_ITER):\n",
    "    result = agent.train()\n",
    "    results.append(result)\n",
    "    \n",
    "    episode = {'n': n, \n",
    "               'episode_reward_min': result['episode_reward_min'], \n",
    "               'episode_reward_mean': result['episode_reward_mean'], \n",
    "               'episode_reward_max': result['episode_reward_max'],  \n",
    "               'episode_len_mean': result['episode_len_mean']}\n",
    "    \n",
    "    episode_data.append(episode)\n",
    "    episode_json.append(json.dumps(episode))\n",
    "    file_name = agent.save(checkpoint_root)\n",
    "    \n",
    "    print(f'{n:3d}: Min/Mean/Max reward: {result[\"episode_reward_min\"]:8.4f}/{result[\"episode_reward_mean\"]:8.4f}/{result[\"episode_reward_max\"]:8.4f}. Checkpoint saved to {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "tf210ray101bj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
